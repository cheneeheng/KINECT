/*
 * main.cpp
 *
 *  Created on: Dec 6, 2010
 *      Author: papazov
 */


#include "dataDeclaration.h"

// image variables
cv::Mat rgb_global1 = cv::Mat::zeros(480,640,CV_8UC3);
cv::Mat rgb_global2 = cv::Mat::zeros(480,640,CV_8UC3);
cv::Mat rgb_global3 = cv::Mat::zeros(480,640,CV_8UC3);
cv::Mat rgb_global4 = cv::Mat::zeros(480,640,CV_8UC3);
cv::Mat depth_global,cloud_global;
cv::Mat mask_head_global = cv::Mat::zeros(480,640,CV_8UC1);
cv::Mat mask_hand_global = cv::Mat::zeros(480,640,CV_8UC1);
cv::Mat mask_obj_global  = cv::Mat::zeros(480,640,CV_8UC1);
std::vector<cv::Vec3f> marker_center_global;
cv::Vec4f plane_global;
cv::Rect object_blob_global;
float frame_number_global = 0.0;
bool contact_obj = false;
int  contact_marker = 0;
cv::Vec3f single_point_obj_global;

// threads
int MAX = 3;
sem_t mutex1,mutex2,mutex3,mutex4,mutex5,mutex6,mutex7;
sem_t lock_t1,lock_t2,lock_t3,lock_t4,lock_t5,lock_t6;

bool flag_thres = true;
bool flag_plane = false;
bool flag_marker = false; int marker_num = 2;

// option flags
//#define FLAG_RGB
//#define FLAG_DEPTH
//#define FLAG_FACE
//#define FLAG_MARKER
//#define FLAG_PLANE
#define FLAG_OBJECT
#define FLAG_HAND
#define FLAG_THREAD
#define FLAG_WRITE


//====================================================================================================================================
// [THREAD 1 : KINECT]*********************************************************
void* kinectGrab(void* v_kinect)
{
  cv::VideoCapture * kinect = reinterpret_cast<cv::VideoCapture *>(v_kinect);

  cv::Mat depth_image = cv::Mat::zeros(480,640,CV_8UC3);

  struct timeval start_time, end_time;
  int c = 0;

  while(true)
  {
    if(c==0) gettimeofday(&start_time, NULL);
    
    sem_wait(&lock_t1);
    sem_wait(&lock_t1);
    sem_wait(&lock_t1);
    sem_wait(&mutex1);

    kinect->grab();

    kinect->retrieve(rgb_global1,CV_CAP_OPENNI_BGR_IMAGE);
    rgb_global2 = rgb_global1.clone();
    rgb_global1.clone().rowRange(225,480).copyTo(rgb_global3.rowRange(225,480));
    rgb_global4 = rgb_global1.clone();

    kinect->retrieve(depth_global,CV_CAP_OPENNI_DEPTH_MAP);
    kinect->retrieve(cloud_global,CV_CAP_OPENNI_POINT_CLOUD_MAP);

#ifdef FLAG_DEPTH
    depthImaging(depth_image,depth_global,mGamma);
    cv::imshow("depth",depth_image); cvWaitKey(1);
#endif

#ifdef FLAG_RGB
    cv::imshow("rgb",rgb_global1); cvWaitKey(1);
#endif

    sem_post(&mutex1);
    sem_post(&lock_t2);
    sem_post(&lock_t3);
    sem_post(&lock_t5);

    c++;
    if(c>=10)
    {
      c = 0;
      gettimeofday(&end_time, NULL);
      std::cout << 10/ ((end_time.tv_sec - start_time.tv_sec) + 
                      (end_time.tv_usec- start_time.tv_usec) * 1e-6) 
	        << " [Hz]"<< std::endl;
    }
  }
  return 0;
}


//====================================================================================================================================
// [THREAD 2 : OBJECT DETECTOR]************************************************
void* objectDetector(void* arg)
{
  int hue_range_obj[2], sat_range_obj[2];
//  hue_range_obj[0] = 115; hue_range_obj[1] = 132;
//  sat_range_obj[0] = 133; sat_range_obj[1] = 255;

//red bar
//  hue_range_obj[0] = 116; hue_range_obj[1] = 138;
//  sat_range_obj[0] = 199; sat_range_obj[1] = 255;

// blue board
//  hue_range_obj[0] = 0; hue_range_obj[1] = 81;
//  sat_range_obj[0] = 110; sat_range_obj[1] = 168;

// light green cup
//  hue_range_obj[0] = 66; hue_range_obj[1] = 93;
//  sat_range_obj[0] = 31; sat_range_obj[1] = 77;

// green cup
//  hue_range_obj[0] = 77; hue_range_obj[1] = 98;
//  sat_range_obj[0] = 76; sat_range_obj[1] = 214;

// yellow plyers
  hue_range_obj[0] = 80; hue_range_obj[1] = 102;
  sat_range_obj[0] = 135; sat_range_obj[1] = 255;

// yellow Banana
//  hue_range_obj[0] = 72; hue_range_obj[1] = 100;
//  sat_range_obj[0] = 135; sat_range_obj[1] = 255;

// red apple
//  hue_range_obj[0] = 106; hue_range_obj[1] = 140;
//  sat_range_obj[0] = 130; sat_range_obj[1] = 209;

// blue screwdriver
//  hue_range_obj[0] = 0; hue_range_obj[1] = 54;
//  sat_range_obj[0] = 140; sat_range_obj[1] = 184;

  cv::Mat seg_mask(480,640,CV_8UC1);
  cv::Rect box_obj;

  while(true)
  {
    sem_wait(&lock_t2);
    sem_wait(&mutex2);

    segmentHSVEDIT(rgb_global2, seg_mask,
                   hue_range_obj[1], hue_range_obj[0],
                   sat_range_obj[1], sat_range_obj[0]);
    noiseRemove(seg_mask,mask_obj_global,box_obj);
    object_blob_global = box_obj;

#ifdef FLAG_OBJECT
    cv::Mat rgb_tmp = cv::Mat::zeros(480,640, CV_8UC3);
    rgb_global1.copyTo(rgb_tmp, mask_obj_global);
    cv::imshow("rgb_o",rgb_tmp); cvWaitKey(1);
#endif      

    sem_post(&mutex2);
    sem_post(&lock_t1);
  }
  return 0;
}


//====================================================================================================================================
// [THREAD 3 : HAND DETECTOR]**************************************************
void* handDetector(void* arg)
{ 
  // Crop Threshold
  int hue_range_hand[2], sat_range_hand[2];
  hue_range_hand[0] = 102; hue_range_hand[1] = 122;
  sat_range_hand[0] = 69 ; sat_range_hand[1] = 150;

  // Variable init
  cv::Mat seg_mask(480,640,CV_8UC1);
  cv::Mat img_no_head = cv::Mat::zeros(480,640,CV_8UC3);
  cv::Rect box_hand;

  while(true)
  {
    sem_wait(&lock_t3);
    sem_wait(&mutex3);

    segmentHSVEDIT(rgb_global3, seg_mask, 
                   hue_range_hand[1], hue_range_hand[0],
    		   sat_range_hand[1], sat_range_hand[0]);
    noiseRemove(seg_mask,mask_hand_global,box_hand);
    //noiseRemoveBox(seg_mask,mask_hand_global,box_hand);

#ifdef FLAG_HAND
    cv::Mat rgb_tmp = cv::Mat::zeros(480,640, CV_8UC3);
    rgb_global1.copyTo(rgb_tmp, mask_hand_global);
    cv::imshow("rgb_h",rgb_tmp); cvWaitKey(1);
#endif

    sem_post(&mutex3);
    sem_post(&lock_t1);
  }
  return 0;
}

//====================================================================================================================================
// [THREAD 4 : FACE DETECTOR]**************************************************
void* faceDetector(void* arg)
{
  //Load the cascade for face detector
  std::string face_cascade_name = "lbpcascade_frontalface.xml";
  cv::CascadeClassifier face_cascade;
  if(!face_cascade.load(face_cascade_name))
    printf("--(!)Error loading face cascade\n");

  std::vector<cv::Rect> faces;

  while(true)
  {
    sem_wait(&mutex4);

    faces = detectFaceAndEyes(rgb_global4, face_cascade);

#ifdef FLAG_FACE
    cv::imshow("face",rgb_global4); cvWaitKey(1);
#endif

    sem_post(&mutex4);
  }
  return 0;
}

//====================================================================================================================================
// [THREAD 5 : CONTACT DETECTOR]***********************************************
void* contactDetector(void* arg)
{
  cv::Mat img_depth(480,640,CV_8UC1);
  cv::Mat img_sub(480,640,CV_8UC1);
  cv::Rect blob_def;
  cv::Mat cloud_mask,cloud_mask2;

  float contact_sub, contact_diff;
  int begin, ends;
  bool flag = true;
  bool flag_contact_obj = false;

  Ipp8u ippi_depth_default[640*480] = {0};
  Ipp8u ippi_depth_tmp[640*480] = {0};
  Ipp8u ippi_depth_image[640*480] = {0};
  IppiSize roi_size;      roi_size.width = 640;    roi_size.height = 480;
  IppiSize roi_size_blob; roi_size_blob.width = 1; roi_size_blob.height = 1;
  IppiPoint roi_point;    roi_point.x = 0;         roi_point.x = 0;

  int c = 0;

  while(true)
  {
      sem_wait(&lock_t5);
      sem_wait(&mutex5);

     //[KINECT DEPTH]*********************************************************
      u_char      *ptr=img_depth.data;
      uint16_t    *depth=(uint16_t*)depth_global.data;
      for(int i=0;i<640*480;i++) ptr[i] = depth[i]/2048.00 * 255;
      //*********************************************************[KINECT DEPTH]

      //[DEFAULT SCENE]********************************************************
      if(flag){
        ippiCopy_8u_C1R(img_depth.data,640, 
                        ippi_depth_default,640,roi_size);
        roi_size_blob.width  = object_blob_global.size().width ;
        roi_size_blob.height = object_blob_global.size().height;
        roi_point.x = object_blob_global.x;
        roi_point.y = object_blob_global.y;
        begin = 640*roi_point.y+roi_point.x;
        ends  = 640*(roi_point.y+roi_size_blob.height)+
                    (roi_point.x+roi_size_blob.width);
        if(roi_point.x>0 && roi_point.y>0) flag = false;
      }
      //********************************************************[DEFAULT SCENE]

      //[OBJECT POINT]*********************************************************
      cloud_global.copyTo(cloud_mask,mask_obj_global); //taking the obj only
      cloud_mask(object_blob_global).copyTo(cloud_mask2); // reducing the search area
      //cloud_global(object_blob_global).copyTo(cloud_mask);
      pointCloudTrajectory(cloud_mask2, single_point_obj_global);
      cloud_mask.release();
      cloud_mask2.release();
      //*********************************************************[OBJECT POINT]

      //[OBJECT CONTACT]*******************************************************    
      if(contactCheck(mask_hand_global,mask_obj_global)){
        //if(!flag_contact_obj){
        if(1){
          ippiSub_8u_C1RSfs (img_depth.data+640*roi_point.y+roi_point.x, 640,
                             ippi_depth_default+640*roi_point.y+roi_point.x, 640,
                             ippi_depth_tmp,640,
                             roi_size_blob,0);
          ippiMulC_8u_C1RSfs(ippi_depth_tmp,640,
                             1, // multiplication factor so that image is viewable
                             ippi_depth_image+640*roi_point.y+roi_point.x,640,
                             roi_size,0);
          ippiCopy_8u_C1R(ippi_depth_image,640,img_sub.data,640,roi_size);

          contact_sub  = 0.0;
          for(int i=begin;i<ends;i++) contact_sub += img_sub.data[i]; 
          contact_sub = contact_sub/(ends-begin);

          if(contact_sub>0 && contact_sub< 0.8){ //0.8
            contact_obj = true;
            flag_contact_obj = true;
          }
          else contact_obj = false;
        }
        else contact_obj = true;     
      }
      else contact_obj = false;

      if(object_blob_global.y < 241) {contact_obj = true;} // face prevention*/
      //*******************************************************[OBJECT CONTACT]
/*
      //[MARKER CONTACT]******************************************************* 
      if(flag_marker){
        contact_marker = markerContact(marker_center_global, 
                                       plane_global, 
                                       single_point_obj_global);
      }
      //*******************************************************[MARKER CONTACT]
*/  
//    printf("CONTACT : %d     %d\n", contact_obj, contact_marker);
    c++;
    if(c>=10){
      printf("CONTACT : %d     %d       CONTACTVAL : %f\n", contact_obj, flag_contact_obj, contact_sub);
      c = 0;
    }

      sem_post(&mutex5);
      sem_post(&lock_t1);
  }
  return 0;
}

//====================================================================================================================================
// [THREAD 6 : WRITE DATA]*****************************************************
void* writeData(void* arg)
{
  return 0;
}


//====================================================================================================================================


int main()
{

  cv::Mat rgb_image,disp_depth,point_cloud,depth_image(480,640,CV_8UC3);
	
  // The kinect3d object        
  cv::VideoCapture kinect(CV_CAP_OPENNI2); printf("Starting Kinect ...\n");

  // Depth value processing
  uint16_t mGamma[2048];
  for( int i=0;i<2048;++i )
    { float v=i/2048.0; v=powf(v, 3)*6; mGamma[i]=v*6*256;}   

  // Run the visualization
#ifdef FLAG_DEPTH
  cv::namedWindow("depth");
#endif
#ifdef FLAG_RGB
  cv::namedWindow("rgb");
#endif
#ifdef FLAG_HAND
  cv::namedWindow("rgb_h");
  cvMoveWindow("rgb_h",0,0);
#endif
#ifdef FLAG_OBJECT
  cv::namedWindow("rgb_o");
  cvMoveWindow("rgb_o",0,490);  
#endif
#ifdef FLAG_PLANE
  cv::namedWindow("plane");
#endif
#ifdef FLAG_MARKER
  cv::namedWindow("rgb_m");
#endif
#ifdef FLAG_FACE
  cv::namedWindow("face");
#endif

#ifdef FLAG_THREAD
  // Start multithread
  pthread_t thread_kinectGrab,
            thread_objDetector,
            thread_handDetector,
            thread_faceDetector,
            thread_contactDetector,
            thread_writeData;

  sem_init(&lock_t1, 0, MAX);
  sem_init(&lock_t2, 0, 0);
  sem_init(&lock_t3, 0, 0);
  sem_init(&lock_t4, 0, 0);
  sem_init(&lock_t5, 0, 0);
  sem_init(&lock_t6, 0, 1);
  sem_init(&mutex1, 0, 1);
  sem_init(&mutex2, 0, 1);
  sem_init(&mutex3, 0, 1);
  sem_init(&mutex4, 0, 1);
  sem_init(&mutex5, 0, 1);
  sem_init(&mutex6, 0, 1);
  sem_init(&mutex7, 0, 1);

  pthread_attr_t attr;
  cpu_set_t cpus;
  pthread_attr_init(&attr);

  CPU_ZERO(&cpus);
  CPU_SET(1, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);
  pthread_create(&thread_kinectGrab, &attr, kinectGrab, &kinect);

  CPU_ZERO(&cpus);
  CPU_SET(2, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);
  pthread_create(&thread_objDetector, &attr, objectDetector, NULL);

  CPU_ZERO(&cpus);
  CPU_SET(3, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);    
  pthread_create(&thread_handDetector, &attr, handDetector, NULL);

  CPU_ZERO(&cpus);
  CPU_SET(4, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);    
  pthread_create(&thread_faceDetector, &attr, faceDetector, NULL);

  CPU_ZERO(&cpus);
  CPU_SET(5, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);    
  pthread_create(&thread_contactDetector, &attr, contactDetector, NULL);

  CPU_ZERO(&cpus);
  CPU_SET(6, &cpus);
  pthread_attr_setaffinity_np(&attr, sizeof(cpu_set_t), &cpus);    
  pthread_create(&thread_writeData, &attr, writeData, NULL);

  pthread_join(thread_kinectGrab, NULL);
  pthread_join(thread_objDetector, NULL);
  pthread_join(thread_handDetector, NULL);
  pthread_join(thread_faceDetector, NULL);
  pthread_join(thread_contactDetector, NULL);
  pthread_join(thread_writeData, NULL);

  //printf("MAIN THREAD ON CORE : %d\n",sched_getcpu()); 

#else 
  while(true)
  {
    kinect.grab();
    kinect.retrieve(rgb_global,CV_CAP_OPENNI_BGR_IMAGE);
//    kinect.retrieve(depth_global,CV_CAP_OPENNI_DEPTH_MAP);
//    kinect.retrieve(cloud_global,CV_CAP_OPENNI_POINT_CLOUD_MAP);

    cv::imshow("rgb_global",rgb_global); cvWaitKey(1);

    if(flag_thres)
    {
      cv::imwrite( "test.png" , rgb_global );
      int hue_range[2], sat_range[2];
      cv::Mat img = cv::imread("test.png");
      getColorThreshold(img, hue_range, sat_range);
      printf("Final Calibration values:\nhue = %d %d\nsat = %d %d\n",
              hue_range[0],hue_range[1],
              sat_range[0],sat_range[1]);
      cv::imshow("rgb",img);
      std::cout << "press <s> to stop kinect.\n";
      char k = cv::waitKey(0); if (k == 's') break; 
    }   
  }
#endif 

  return 0;
}

























/*
#include <vtkPointSource.h>
#include <vtkPolyData.h>
#include <vtkSmartPointer.h>
#include <vtkPolyDataMapper.h>
#include <vtkActor.h>
#include <vtkRenderWindow.h>
#include <vtkRenderer.h>
#include <vtkRenderWindowInteractor.h>
 
int main(int, char *[])
{

  cv::VideoCapture * kinect = reinterpret_cast<cv::VideoCapture *>(v_kinect);

  cv::Mat cloud_global;

    kinect.grab();
    kinect.retrieve(cloud_global,CV_CAP_OPENNI_POINT_CLOUD_MAP);



  // Create a point cloud
  vtkSmartPointer<vtkPointSource> pointSource =
    vtkSmartPointer<vtkPointSource>::New();
  pointSource->SetCenter(0.0, 0.0, 0.0);
  pointSource->SetNumberOfPoints(50);
  pointSource->SetRadius(5.0);
  pointSource->Update();
 
  // Create a mapper and actor
  vtkSmartPointer<vtkPolyDataMapper> mapper =
    vtkSmartPointer<vtkPolyDataMapper>::New();
  mapper->SetInputConnection(pointSource->GetOutputPort());
 
  vtkSmartPointer<vtkActor> actor =
    vtkSmartPointer<vtkActor>::New();
  actor->SetMapper(mapper);
 
  // Create a renderer, render window, and interactor
  vtkSmartPointer<vtkRenderer> renderer =
    vtkSmartPointer<vtkRenderer>::New();
  vtkSmartPointer<vtkRenderWindow> renderWindow =
    vtkSmartPointer<vtkRenderWindow>::New();
  renderWindow->AddRenderer(renderer);
  vtkSmartPointer<vtkRenderWindowInteractor> renderWindowInteractor =
    vtkSmartPointer<vtkRenderWindowInteractor>::New();
  renderWindowInteractor->SetRenderWindow(renderWindow);
 
  // Add the actor to the scene
  renderer->AddActor(actor);
  renderer->SetBackground(.3, .6, .3); // Background color green
 
  // Render and interact
  renderWindow->Render();
  renderWindowInteractor->Start();
 
  return EXIT_SUCCESS;
}
*/

